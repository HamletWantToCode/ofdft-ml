Introduction
============

OFDFT-ML is intended to use machine learning (ML) techniques to leverage the original Hohenberg-Kohn
density function theory (DFT).

In quantum mechanics, the observables of quantum system can be represented as a unique functional
of the groundstate electron density :math:`n` :

.. math::
   \mathcal{O}=\langle\Psi_{[n]}|\hat{\mathcal{O}}|\Psi_{[n]}\rangle\equiv\mathcal{O}[n]

traditionally, we will first solve for :math:`\Psi` , which is the groundstate wavefunction of 
the quantum system, and compute the groundstate electron density as the inner product of :math:`\Psi` .
This approach requires us to use the concept of electron orbitals to formulate the wavefunction, and 
the computation complexity of resulting algorithm is ...... . Another approach is offered by the 
`Hohenberg-Kohn theorem <https://en.wikipedia.org/wiki/Density_functional_theory#Hohenberg%E2%80%93Kohn_theorems>`_ ,
which indicate that the total energy of the quantum system is also a unique functional of the electron density,
and we can solve for groundstate electron density by finding the global minimum of the total energy functional.

However, it's hard to write the explicit form of kinetic energy functional w.r.t the electron density. Unlike the 
exchange correlation energy, which only account for 3% of the total energy, kinetic energy accounts for 50% of the 
total energy, any error in estimating the kinetic energy will seriously affects the total energy. Therefore, to leverage
the orbital-free nature of Hohenberg-Kohn DFT, it's crutial for us to estimate the kinetic energy correctly.

The existing paradiagms for studying OFDFT are Thomas-Fermi theory and it's corrections, it's intuitive and motivated 
by physics law but fail to answer the questions of ...... . If we think about functional analysis and treate the electron
density as a vector in function space, the problem of estimating the kinetic energy functional can be regarded as a 
multivariate regression problem, but unlike the textbook level regression, here we may need to deal with hundred or thousand
of variables, and the prior knowledge about the fitting function is limited. Machine learning is popular for processing
data in astrophysics and particle physics, where data is high dimensional in nature. Therefore, we considered machine 
learning as a promising candidate for realizing OFDFT. Introducing machine learning technique to DFT study is credited to Professor Kieron Burke, in his pioneering paper in 2012 ([1]_), he consider textbook instance, electron in a finite well, and effectively learn the kinetic energy functional using kernel ridge regression. 

Apart from atomic and molecular physics, DFT is also widely used in material simulations. To simplify the problem, we consider 
to estimate the kinetic energy functional of electron in 1D periodic lattice, and ignore the interaction between electrons. The
learning dataset is generated by **quantum** module inside the OFDFT-ML package, there are two major parts of **quantum** module,
first is a potential generator, which will generate 1D periodic potential of random shape and strength. The other is a Schrodinger
equation solver, which solves for kinetic energy and groundstate electron density of the 1D lattice. 

After collecting groundstate electron density and kinetic into a database, we will set the electron density (in real space grid) 
as features, and kinetic energy as target, split the whole database into training and testing dataset, then construct our 
machine learning model on the training dataset, then test the performance on the testing dataset. 

The **statslib** module provides methods needed to build a machine learning workflow. Our workflow contains two successive steps, 
the first is a dimension reduction algorithm, it's difficult to find the relation between target and features if the feature space is
high dimensional. High dimensional data tends to be sparse in nature, which is known as `curse of dimensionality <https://en.wikipedia.org/wiki/Curse_of_dimensionality>`_ ([2]_). In this case, we use principal component analysis (PCA) to model the original feature
space as a low dimensional hyperplane. After transforming the original data into a low dimensional representation, we will fit a
regression model on the data, we decided to use kernel machines here, since they are data driven and the fitted functional is able 
to be writen in a closed form:

.. math::
   T_{ML}[n] = \sum_{i=1}^N\alpha_i K(n, n_i)

To achieve the OFDFT, we need to solve Euler-Lagrangian (EL) equation for groundstate electron density of a given external potential,
and this requires us to find the functional derivative of kinetic energy. The machine learned functional derivative can be represented 
as:

.. math::
   \frac{\delta T_{ML}[n]}{\delta n(x)}=\sum_{i=1}^N\alpha_i\frac{\delta K(n, n_i)}{\delta n(x)}

Since we were fitting the functional in a low dimensional feature space, we need to transform this derivative back to the original
space. A nice thing about PCA is that it's linear transformation, therefore, the inverse transform is just the inverse of the 
forward transform.

The EL equation is known as:

.. math::
   \frac{\delta T_{ML}}{\delta n(x)}+V(x)-\mu=0

and can be solved iteratively using gradient descent method:

.. math::
   n^{(t+1)}(x)=n^{(t)}(x)-\epsilon\left(\frac{\delta T_{ML}}{\delta n^{(t)}(x)}+V(x)-\mu\right)



References
----------

.. [1] `Finding Density Functionals with Machine Learning <https://link.aps.org/doi/10.1103/PhysRevLett.108.253002>`_
.. [2] `The Curse of Dimensionality for Local Kernel Machines <https://pdfs.semanticscholar.org/9bfc/f812b249d570823c6a0dff4a4781a40524d1.pdf>`_

